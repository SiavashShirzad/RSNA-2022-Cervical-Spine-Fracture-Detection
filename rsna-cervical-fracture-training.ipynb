{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T09:23:35.710905Z","iopub.status.busy":"2022-10-09T09:23:35.710602Z","iopub.status.idle":"2022-10-09T09:23:42.202367Z","shell.execute_reply":"2022-10-09T09:23:42.201349Z","shell.execute_reply.started":"2022-10-09T09:23:35.710880Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import nibabel as nib\n","from tensorflow import keras\n","import tensorflow_addons as tfa\n","import random\n","from scipy import ndimage\n","from tensorflow import keras\n","import os\n","import pydicom as dcm\n","import scipy\n","import cv2\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def window_image(img, minn,maxx, intercept, slope, rescale=True):\n","    img = (img*slope +intercept) \n","    \n","    img[img<minn] = minn \n","    img[img>maxx] = maxx \n","    if rescale: \n","        img = (img - minn) / (maxx - minn)\n","    return img\n","    \n","def get_first_of_dicom_field_as_int(x):\n","    if type(x) == dcm.multival.MultiValue: return int(x[0])\n","    else: return int(x)\n","    \n","def get_windowing(data):\n","    dicom_fields = [data[('0028','1050')].value,\n","                    data[('0028','1051')].value,\n","                    data[('0028','1052')].value,\n","                    data[('0028','1053')].value]\n","    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def channeling(img1, img2, img3):\n","    return np.stack([img1, img2, img3], axis=-1)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def load_image(path):\n","    data_path = '../../Downloads/rsna-2022-cervical-spine-fracture-detection/train_images/'\n","    UID = path.split('/')[-1][:-7]+\"/\"\n","    data = dcm.dcmread(data_path+UID+os.listdir(data_path+UID)[0])\n","    _, _, intercept, slope = get_windowing(data)\n","    img = nib.load(path)\n","    img = img.get_fdata()\n","    return img, intercept, slope"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def load_meta(UID):\n","    data_path = '../../Downloads/rsna-2022-cervical-spine-fracture-detection/train_images/'\n","    data = dcm.dcmread(data_path+UID+'/'+os.listdir(data_path+UID)[0])\n","    _, _, intercept, slope = get_windowing(data)\n","    return intercept, slope"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"../../Downloads/rsna-2022-cervical-spine-fracture-detection/train.csv\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"]}],"source":["base_model = tf.keras.models.load_model('./feature_extractor/feature_extractor/') # (None, 256, 256, 3)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T09:23:42.240412Z","iopub.status.busy":"2022-10-09T09:23:42.239771Z","iopub.status.idle":"2022-10-09T09:23:42.250749Z","shell.execute_reply":"2022-10-09T09:23:42.249079Z","shell.execute_reply.started":"2022-10-09T09:23:42.240375Z"},"trusted":true},"outputs":[],"source":["n_image_list = np.arange(0, df.shape[0])\n","random_n_image_list = np.random.choice(n_image_list, df.shape[0], replace=False)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["A subdirectory or file extracted_features already exists.\n"]}],"source":["!mkdir extracted_features"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2019/2019 [1:45:44<00:00,  3.14s/it]\n"]}],"source":["for image in tqdm(df['StudyInstanceUID']):\n","        try:\n","                co = df[df['StudyInstanceUID']==image]['patient_overall'].values[0]\n","                c1 = df[df['StudyInstanceUID']==image]['C1'].values[0]\n","                c2 = df[df['StudyInstanceUID']==image]['C2'].values[0]\n","                c3 = df[df['StudyInstanceUID']==image]['C3'].values[0]\n","                c4 = df[df['StudyInstanceUID']==image]['C4'].values[0]\n","                c5 = df[df['StudyInstanceUID']==image]['C5'].values[0]\n","                c6 = df[df['StudyInstanceUID']==image]['C6'].values[0]\n","                c7 = df[df['StudyInstanceUID']==image]['C7'].values[0]\n","                ct = nib.load('../storage/'+image+'.nii.gz')\n","                ct = ct.get_fdata()\n","                ct = scipy.ndimage.zoom(ct, (256/ct.shape[0],1,1), order=1)\n","                ct = np.transpose(ct, axes=[2,0,1])[68:188:2]\n","                intercept, slope = load_meta(image)\n","                ct1 = window_image(ct,100,600,intercept,slope)\n","                ct2 = window_image(ct,600,1100,intercept,slope)\n","                ct3 = window_image(ct,1100,1600,intercept,slope)\n","                ct = channeling(ct1, ct2, ct3)\n","                features = np.array(base_model(ct))\n","                np.save('../RSNA-2022-Cervical-Spine-Fracture-Detection/extracted_features/'+image+'.npy', features)\n","        except:\n","                continue\n","        "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def data_gen():\n","    for image in df['StudyInstanceUID'][:1800]:\n","        try:\n","            co = df[df['StudyInstanceUID']==image]['patient_overall'].values[0]\n","            c1 = df[df['StudyInstanceUID']==image]['C1'].values[0]\n","            c2 = df[df['StudyInstanceUID']==image]['C2'].values[0]\n","            c3 = df[df['StudyInstanceUID']==image]['C3'].values[0]\n","            c4 = df[df['StudyInstanceUID']==image]['C4'].values[0]\n","            c5 = df[df['StudyInstanceUID']==image]['C5'].values[0]\n","            c6 = df[df['StudyInstanceUID']==image]['C6'].values[0]\n","            c7 = df[df['StudyInstanceUID']==image]['C7'].values[0]\n","            \n","            features = np.load('../RSNA-2022-Cervical-Spine-Fracture-Detection/extracted_features/'+image+'.npy')\n","\n","            yield ({\"input_1\": features},\n","                  {'co': co, \n","                                        'c1': c1,\n","                                        'c2': c2,\n","                                        'c3': c3,\n","                                        'c4': c4,\n","                                        'c5': c5,\n","                                        'c6': c6,\n","                                        'c7': c7,},\n","                      {'co': 14, \n","                                    'c1': c1+1,\n","                                    'c2': c2+1,\n","                                    'c3': c3+1,\n","                                    'c4': c4+1,\n","                                    'c5': c5+1,\n","                                    'c6': c6+1,\n","                                    'c7': c7+1})\n","        except:\n","            continue\n","\n","\n","def test_gen():\n","    for image in df['StudyInstanceUID'][1880:]:\n","        try:\n","            co = df[df['StudyInstanceUID']==image]['patient_overall'].values[0]\n","            c1 = df[df['StudyInstanceUID']==image]['C1'].values[0]\n","            c2 = df[df['StudyInstanceUID']==image]['C2'].values[0]\n","            c3 = df[df['StudyInstanceUID']==image]['C3'].values[0]\n","            c4 = df[df['StudyInstanceUID']==image]['C4'].values[0]\n","            c5 = df[df['StudyInstanceUID']==image]['C5'].values[0]\n","            c6 = df[df['StudyInstanceUID']==image]['C6'].values[0]\n","            c7 = df[df['StudyInstanceUID']==image]['C7'].values[0]\n","            features = np.load('../RSNA-2022-Cervical-Spine-Fracture-Detection/extracted_features/'+image+'.npy')\n","\n","            yield ({\"input_1\": features},\n","                  {'co': co, \n","                                        'c1': c1,\n","                                        'c2': c2,\n","                                        'c3': c3,\n","                                        'c4': c4,\n","                                        'c5': c5,\n","                                        'c6': c6,\n","                                        'c7': c7,},\n","                      {'co': 14, \n","                                    'c1': c1+1,\n","                                    'c2': c2+1,\n","                                    'c3': c3+1,\n","                                    'c4': c4+1,\n","                                    'c5': c5+1,\n","                                    'c6': c6+1,\n","                                    'c7': c7+1})\n","        except:\n","            continue"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["dataset = tf.data.Dataset.from_generator(\n","     data_gen,\n","     ({\"input_1\":tf.float32}, \n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8},\n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8}),\n","    ({\"input_1\":tf.TensorShape([60,2048])}, \n","     {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])},\n","    {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])})\n",")\n","\n","testset = tf.data.Dataset.from_generator(\n","     test_gen,\n","     ({\"input_1\":tf.float32}, \n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8},\n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8}),\n","    ({\"input_1\":tf.TensorShape([60,2048])}, \n","     {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])},\n","    {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])})\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["dataset = dataset.batch(2)\n","dataset = dataset.prefetch(1)\n","\n","\n","testset = testset.batch(2)\n","testset = testset.prefetch(1)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:50:56.796337Z","iopub.status.busy":"2022-10-09T11:50:56.795975Z","iopub.status.idle":"2022-10-09T11:51:18.549905Z","shell.execute_reply":"2022-10-09T11:51:18.548813Z","shell.execute_reply.started":"2022-10-09T11:50:56.796309Z"},"trusted":true},"outputs":[],"source":["input1 = keras.Input((60, 2048),name = \"input_1\")\n","\n","s = keras.layers.BatchNormalization()(input1)\n","s = keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=True))(s)\n","s = keras.layers.Dense(2048, activation='relu')(s)\n","s = keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=False))(s)\n","\n","s = keras.layers.BatchNormalization()(s)\n","\n","s3 = keras.layers.Dense(512, activation='relu')(s)\n","s3 = keras.layers.BatchNormalization()(s3)\n","s3 = keras.layers.Dense(256, activation='relu')(s3)\n","s3 = keras.layers.BatchNormalization()(s3)\n","s3 = keras.layers.Dense(128, activation='relu')(s3)\n","\n","\n","outputo = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"co\")(s3)\n","output1 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c1\")(s3)\n","output2 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c2\")(s3)\n","output3 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c3\")(s3)\n","output4 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c4\")(s3)\n","output5 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c5\")(s3)\n","output6 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c6\")(s3)\n","output7 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c7\")(s3)\n","                                               \n","s_model = keras.models.Model(inputs=input1, outputs=[outputo,output1,output2,output3,output4,output5,output6,output7])"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:51:18.557697Z","iopub.status.busy":"2022-10-09T11:51:18.555271Z","iopub.status.idle":"2022-10-09T11:51:18.577857Z","shell.execute_reply":"2022-10-09T11:51:18.576718Z","shell.execute_reply.started":"2022-10-09T11:51:18.557643Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 60, 2048)]   0           []                               \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 60, 2048)    8192        ['input_1[0][0]']                \n"," alization)                                                                                       \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 60, 4096)     67125248    ['batch_normalization[0][0]']    \n","                                                                                                  \n"," dense (Dense)                  (None, 60, 2048)     8390656     ['bidirectional[0][0]']          \n","                                                                                                  \n"," bidirectional_1 (Bidirectional  (None, 4096)        67125248    ['dense[0][0]']                  \n"," )                                                                                                \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 4096)        16384       ['bidirectional_1[0][0]']        \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_1 (Dense)                (None, 512)          2097664     ['batch_normalization_1[0][0]']  \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense_1[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_2 (Dense)                (None, 256)          131328      ['batch_normalization_2[0][0]']  \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_2[0][0]']                \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_3 (Dense)                (None, 128)          32896       ['batch_normalization_3[0][0]']  \n","                                                                                                  \n"," co (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c1 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c2 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c3 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c4 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c5 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c6 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n"," c7 (Dense)                     (None, 1)            129         ['dense_3[0][0]']                \n","                                                                                                  \n","==================================================================================================\n","Total params: 144,931,720\n","Trainable params: 144,917,896\n","Non-trainable params: 13,824\n","__________________________________________________________________________________________________\n"]}],"source":["s_model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def lr_schedule(epoch, lr):\n","    return lr/(epoch+1)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:36.272741Z","iopub.status.busy":"2022-10-09T11:52:36.271752Z","iopub.status.idle":"2022-10-09T11:52:36.293719Z","shell.execute_reply":"2022-10-09T11:52:36.292702Z","shell.execute_reply.started":"2022-10-09T11:52:36.272689Z"},"trusted":true},"outputs":[],"source":["opt = tfa.optimizers.AdamW(\n","    weight_decay=1e-4,\n","    learning_rate = 0.001,\n","    beta_1 = 0.9,\n","    beta_2 = 0.999,\n","    epsilon = 1e-07,\n","    name = 'AdamW',\n",")\n","loss = tf.keras.losses.BinaryCrossentropy(\n","#     label_smoothing=0.1, \n","    reduction=tf.keras.losses.Reduction.AUTO,\n","    name='binary_crossentropy'\n",")\n","metrics = [tf.keras.metrics.AUC()]\n","s_model.compile(optimizer=opt,\n","              loss={\"co\": loss, \n","                   \"c1\": loss,\n","                   \"c2\": loss,\n","                   \"c3\": loss,\n","                   \"c4\": loss,\n","                   \"c5\": loss,\n","                   \"c6\": loss,\n","                   \"c7\": loss,},\n","                metrics={\"co\": metrics})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:41.508507Z","iopub.status.busy":"2022-10-09T11:52:41.507517Z","iopub.status.idle":"2022-10-09T11:52:42.603076Z","shell.execute_reply":"2022-10-09T11:52:42.601704Z","shell.execute_reply.started":"2022-10-09T11:52:41.508467Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["A subdirectory or file final_smodel already exists.\n"]}],"source":["!mkdir final_smodel"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:43.515277Z","iopub.status.busy":"2022-10-09T11:52:43.514855Z","iopub.status.idle":"2022-10-09T11:52:43.522206Z","shell.execute_reply":"2022-10-09T11:52:43.520678Z","shell.execute_reply.started":"2022-10-09T11:52:43.515235Z"},"trusted":true},"outputs":[],"source":["model_checkpoint_callback_LASSO = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = './final_smodel/model',\n","    monitor=\"val_loss\",\n","    save_best_only=True,\n","    save_weights_only=True,\n","    mode=\"auto\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:48.837346Z","iopub.status.busy":"2022-10-09T11:52:48.836611Z","iopub.status.idle":"2022-10-09T12:46:18.551801Z","shell.execute_reply":"2022-10-09T12:46:18.543428Z","shell.execute_reply.started":"2022-10-09T11:52:48.837309Z"},"trusted":true},"outputs":[],"source":["history = s_model.fit(dataset, validation_data = testset, epochs=20, callbacks=[model_checkpoint_callback_LASSO, tf.keras.callbacks.LearningRateScheduler(lr_schedule)])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('eon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"7ac21e7c5f840be57102ee0f5398c792063c2a27dc2325b7f7034b34f50df51e"}}},"nbformat":4,"nbformat_minor":4}
