{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T09:23:35.710905Z","iopub.status.busy":"2022-10-09T09:23:35.710602Z","iopub.status.idle":"2022-10-09T09:23:42.202367Z","shell.execute_reply":"2022-10-09T09:23:42.201349Z","shell.execute_reply.started":"2022-10-09T09:23:35.710880Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import nibabel as nib\n","from tensorflow import keras\n","import tensorflow_addons as tfa\n","import random\n","from scipy import ndimage\n","from tensorflow import keras\n","import os\n","import pydicom as dcm\n","import scipy\n","import cv2\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def window_image(img, minn,maxx, intercept, slope, rescale=True):\n","    img = (img*slope +intercept) \n","    \n","    img[img<minn] = minn \n","    img[img>maxx] = maxx \n","    if rescale: \n","        img = (img - minn) / (maxx - minn)\n","    return img\n","    \n","def get_first_of_dicom_field_as_int(x):\n","    if type(x) == dcm.multival.MultiValue: return int(x[0])\n","    else: return int(x)\n","    \n","def get_windowing(data):\n","    dicom_fields = [data[('0028','1050')].value,\n","                    data[('0028','1051')].value,\n","                    data[('0028','1052')].value,\n","                    data[('0028','1053')].value]\n","    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def channeling(img1, img2, img3):\n","    return np.stack([img1, img2, img3], axis=-1)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def load_image(path):\n","    data_path = '../../Downloads/rsna-2022-cervical-spine-fracture-detection/train_images/'\n","    UID = path.split('/')[-1][:-7]+\"/\"\n","    data = dcm.dcmread(data_path+UID+os.listdir(data_path+UID)[0])\n","    _, _, intercept, slope = get_windowing(data)\n","    img = nib.load(path)\n","    img = img.get_fdata()\n","    return img, intercept, slope"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def load_meta(UID):\n","    data_path = '../../Downloads/rsna-2022-cervical-spine-fracture-detection/train_images/'\n","    data = dcm.dcmread(data_path+UID+'/'+os.listdir(data_path+UID)[0])\n","    _, _, intercept, slope = get_windowing(data)\n","    return intercept, slope"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df = pd.read_csv(\"../../Downloads/rsna-2022-cervical-spine-fracture-detection/train.csv\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["base_model = tf.keras.models.load_model('./feature_extractor/feature_extractor/') # (None, 256, 256, 3)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T09:23:42.240412Z","iopub.status.busy":"2022-10-09T09:23:42.239771Z","iopub.status.idle":"2022-10-09T09:23:42.250749Z","shell.execute_reply":"2022-10-09T09:23:42.249079Z","shell.execute_reply.started":"2022-10-09T09:23:42.240375Z"},"trusted":true},"outputs":[],"source":["n_image_list = np.arange(0, df.shape[0])\n","random_n_image_list = np.random.choice(n_image_list, df.shape[0], replace=False)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["A subdirectory or file extracted_features already exists.\n"]}],"source":["!mkdir extracted_features"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2019/2019 [1:45:44<00:00,  3.14s/it]\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["for image in tqdm(df['StudyInstanceUID']):\n","        try:\n","                co = df[df['StudyInstanceUID']==image]['patient_overall'].values[0]\n","                c1 = df[df['StudyInstanceUID']==image]['C1'].values[0]\n","                c2 = df[df['StudyInstanceUID']==image]['C2'].values[0]\n","                c3 = df[df['StudyInstanceUID']==image]['C3'].values[0]\n","                c4 = df[df['StudyInstanceUID']==image]['C4'].values[0]\n","                c5 = df[df['StudyInstanceUID']==image]['C5'].values[0]\n","                c6 = df[df['StudyInstanceUID']==image]['C6'].values[0]\n","                c7 = df[df['StudyInstanceUID']==image]['C7'].values[0]\n","                ct = nib.load('../storage/'+image+'.nii.gz')\n","                ct = ct.get_fdata()\n","                ct = scipy.ndimage.zoom(ct, (256/ct.shape[0],1,1), order=1)\n","                ct = np.transpose(ct, axes=[2,0,1])[68:188:2]\n","                intercept, slope = load_meta(image)\n","                ct1 = window_image(ct,100,600,intercept,slope)\n","                ct2 = window_image(ct,600,1100,intercept,slope)\n","                ct3 = window_image(ct,1100,1600,intercept,slope)\n","                ct = channeling(ct1, ct2, ct3)\n","                features = np.array(base_model(ct))\n","                np.save('../RSNA-2022-Cervical-Spine-Fracture-Detection/extracted_features/'+image+'.npy', features)\n","        except:\n","                continue\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def data_gen():\n","    for image in df['StudyInstanceUID'][:1800]:\n","        try:\n","            co = df[df['StudyInstanceUID']==image]['patient_overall'].values[0]\n","            c1 = df[df['StudyInstanceUID']==image]['C1'].values[0]\n","            c2 = df[df['StudyInstanceUID']==image]['C2'].values[0]\n","            c3 = df[df['StudyInstanceUID']==image]['C3'].values[0]\n","            c4 = df[df['StudyInstanceUID']==image]['C4'].values[0]\n","            c5 = df[df['StudyInstanceUID']==image]['C5'].values[0]\n","            c6 = df[df['StudyInstanceUID']==image]['C6'].values[0]\n","            c7 = df[df['StudyInstanceUID']==image]['C7'].values[0]\n","            \n","            features = np.load('../RSNA-2022-Cervical-Spine-Fracture-Detection/extracted_features/'+image+'.npy')\n","\n","            yield ({\"input_1\": features},\n","                  {'co': co, \n","                                        'c1': c1,\n","                                        'c2': c2,\n","                                        'c3': c3,\n","                                        'c4': c4,\n","                                        'c5': c5,\n","                                        'c6': c6,\n","                                        'c7': c7,},\n","                      {'co': 14, \n","                                    'c1': c1+1,\n","                                    'c2': c2+1,\n","                                    'c3': c3+1,\n","                                    'c4': c4+1,\n","                                    'c5': c5+1,\n","                                    'c6': c6+1,\n","                                    'c7': c7+1})\n","        except:\n","            continue\n","\n","\n","def test_gen():\n","    for image in df['StudyInstanceUID'][1880:]:\n","        try:\n","            co = df[df['StudyInstanceUID']==image]['patient_overall'].values[0]\n","            c1 = df[df['StudyInstanceUID']==image]['C1'].values[0]\n","            c2 = df[df['StudyInstanceUID']==image]['C2'].values[0]\n","            c3 = df[df['StudyInstanceUID']==image]['C3'].values[0]\n","            c4 = df[df['StudyInstanceUID']==image]['C4'].values[0]\n","            c5 = df[df['StudyInstanceUID']==image]['C5'].values[0]\n","            c6 = df[df['StudyInstanceUID']==image]['C6'].values[0]\n","            c7 = df[df['StudyInstanceUID']==image]['C7'].values[0]\n","            features = np.load('../RSNA-2022-Cervical-Spine-Fracture-Detection/extracted_features/'+image+'.npy')\n","\n","            yield ({\"input_1\": features},\n","                  {'co': co, \n","                                        'c1': c1,\n","                                        'c2': c2,\n","                                        'c3': c3,\n","                                        'c4': c4,\n","                                        'c5': c5,\n","                                        'c6': c6,\n","                                        'c7': c7,},\n","                      {'co': 14, \n","                                    'c1': c1+1,\n","                                    'c2': c2+1,\n","                                    'c3': c3+1,\n","                                    'c4': c4+1,\n","                                    'c5': c5+1,\n","                                    'c6': c6+1,\n","                                    'c7': c7+1})\n","        except:\n","            continue"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["dataset = tf.data.Dataset.from_generator(\n","     data_gen,\n","     ({\"input_1\":tf.float32}, \n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8},\n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8}),\n","    ({\"input_1\":tf.TensorShape([60,2048])}, \n","     {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])},\n","    {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])})\n",")\n","\n","testset = tf.data.Dataset.from_generator(\n","     test_gen,\n","     ({\"input_1\":tf.float32}, \n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8},\n","     {'co':tf.int8,\n","     'c1':tf.int8,\n","     'c2':tf.int8,\n","     'c3':tf.int8,\n","     'c4':tf.int8,\n","     'c5':tf.int8,\n","     'c6':tf.int8,\n","     'c7':tf.int8}),\n","    ({\"input_1\":tf.TensorShape([60,2048])}, \n","     {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])},\n","    {\"co\": tf.TensorShape([]), \n","     \"c1\": tf.TensorShape([]),\n","     \"c2\": tf.TensorShape([]),\n","     \"c3\": tf.TensorShape([]),\n","     \"c4\": tf.TensorShape([]),\n","     \"c5\": tf.TensorShape([]),\n","     \"c6\": tf.TensorShape([]),\n","     \"c7\": tf.TensorShape([])})\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["dataset = dataset.batch(5)\n","dataset = dataset.prefetch(1)\n","\n","\n","testset = testset.batch(5)\n","testset = testset.prefetch(1)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:50:56.796337Z","iopub.status.busy":"2022-10-09T11:50:56.795975Z","iopub.status.idle":"2022-10-09T11:51:18.549905Z","shell.execute_reply":"2022-10-09T11:51:18.548813Z","shell.execute_reply.started":"2022-10-09T11:50:56.796309Z"},"trusted":true},"outputs":[],"source":["input1 = keras.Input((60, 2048),name = \"input_1\")\n","\n","x = keras.layers.BatchNormalization()(input1)\n","x = keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=True))(x)\n","x = keras.layers.Dense(2048, activation='relu')(x)\n","x = keras.layers.Bidirectional(keras.layers.LSTM(2048, return_sequences=False))(x)\n","\n","x = tf.keras.layers.Dense(512, activation='relu')(x)\n","x = tf.keras.layers.BatchNormalization()(x)\n","\n","x0 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x0 = tf.keras.layers.Dense(128, activation='relu')(x0)\n","x0 = tf.keras.layers.Dense(32, activation='relu')(x0)\n","\n","x1 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x1 = tf.keras.layers.Dense(128, activation='relu')(x1)\n","x1 = tf.keras.layers.Dense(32, activation='relu')(x1)\n","\n","x2 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x2 = tf.keras.layers.Dense(128, activation='relu')(x2)\n","x2 = tf.keras.layers.Dense(32, activation='relu')(x2)\n","\n","x3 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x3 = tf.keras.layers.Dense(128, activation='relu')(x3)\n","x3 = tf.keras.layers.Dense(32, activation='relu')(x3)\n","\n","x4 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x4 = tf.keras.layers.Dense(128, activation='relu')(x4)\n","x4 = tf.keras.layers.Dense(32, activation='relu')(x4)\n","\n","x5 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x5 = tf.keras.layers.Dense(128, activation='relu')(x5)\n","x5 = tf.keras.layers.Dense(32, activation='relu')(x5)\n","\n","x6 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x6 = tf.keras.layers.Dense(128, activation='relu')(x6)\n","x6 = tf.keras.layers.Dense(32, activation='relu')(x6)\n","\n","x7 = tf.keras.layers.Dense(256, activation='relu')(x)\n","x7 = tf.keras.layers.Dense(128, activation='relu')(x7)\n","x7 = tf.keras.layers.Dense(32, activation='relu')(x7)\n","\n","outputo = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"co\")(x0)\n","output1 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c1\")(x1)\n","output2 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c2\")(x2)\n","output3 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c3\")(x3)\n","output4 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c4\")(x4)\n","output5 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c5\")(x5)\n","output6 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c6\")(x6)\n","output7 = keras.layers.Dense(1 ,activation = 'sigmoid', name=\"c7\")(x7)\n","                                               \n","s_model = keras.models.Model(inputs=input1, outputs=[outputo,output1,output2,output3,output4,output5,output6,output7])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["def lr_schedule(epoch, lr):\n","    return lr/((epoch+2)/2)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:36.272741Z","iopub.status.busy":"2022-10-09T11:52:36.271752Z","iopub.status.idle":"2022-10-09T11:52:36.293719Z","shell.execute_reply":"2022-10-09T11:52:36.292702Z","shell.execute_reply.started":"2022-10-09T11:52:36.272689Z"},"trusted":true},"outputs":[],"source":["opt = tfa.optimizers.AdamW(\n","    weight_decay=1e-4,\n","    learning_rate = 0.001,\n","    beta_1 = 0.9,\n","    beta_2 = 0.999,\n","    epsilon = 1e-07,\n","    name = 'AdamW',\n",")\n","loss = tf.keras.losses.BinaryCrossentropy(\n","#     label_smoothing=0.1, \n","    reduction=tf.keras.losses.Reduction.AUTO,\n","    name='binary_crossentropy'\n",")\n","metrics = [tf.keras.metrics.AUC()]\n","s_model.compile(optimizer=opt,\n","              loss={\"co\": loss, \n","                   \"c1\": loss,\n","                   \"c2\": loss,\n","                   \"c3\": loss,\n","                   \"c4\": loss,\n","                   \"c5\": loss,\n","                   \"c6\": loss,\n","                   \"c7\": loss,},\n","                metrics={\"co\": metrics})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:41.508507Z","iopub.status.busy":"2022-10-09T11:52:41.507517Z","iopub.status.idle":"2022-10-09T11:52:42.603076Z","shell.execute_reply":"2022-10-09T11:52:42.601704Z","shell.execute_reply.started":"2022-10-09T11:52:41.508467Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["A subdirectory or file final_smodel already exists.\n"]}],"source":["!mkdir final_smodel"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:43.515277Z","iopub.status.busy":"2022-10-09T11:52:43.514855Z","iopub.status.idle":"2022-10-09T11:52:43.522206Z","shell.execute_reply":"2022-10-09T11:52:43.520678Z","shell.execute_reply.started":"2022-10-09T11:52:43.515235Z"},"trusted":true},"outputs":[],"source":["model_checkpoint_callback_LASSO = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = './final_smodel/model',\n","    monitor=\"val_loss\",\n","    save_best_only=True,\n","    save_weights_only=True,\n","    mode=\"auto\",\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-10-09T11:52:48.837346Z","iopub.status.busy":"2022-10-09T11:52:48.836611Z","iopub.status.idle":"2022-10-09T12:46:18.551801Z","shell.execute_reply":"2022-10-09T12:46:18.543428Z","shell.execute_reply.started":"2022-10-09T11:52:48.837309Z"},"trusted":true},"outputs":[],"source":["history = s_model.fit(dataset, validation_data = testset, epochs=20, callbacks=[model_checkpoint_callback_LASSO, tf.keras.callbacks.LearningRateScheduler(lr_schedule)])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1d7c1eaf8e0>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["s_model.load_weights('./final_smodel/model')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n","28/28 [==============================] - 3s 86ms/step - loss: 12.8711 - co_loss: 9.2336 - c1_loss: 0.4555 - c2_loss: 0.6635 - c3_loss: 0.1814 - c4_loss: 0.4867 - c5_loss: 0.4134 - c6_loss: 0.6149 - c7_loss: 0.8219 - co_auc: 0.6531\n"]},{"data":{"text/plain":["[12.871099472045898,\n"," 9.233647346496582,\n"," 0.4555373787879944,\n"," 0.6635385155677795,\n"," 0.1814422905445099,\n"," 0.48674824833869934,\n"," 0.41338467597961426,\n"," 0.6149333715438843,\n"," 0.8218652009963989,\n"," 0.6530655026435852]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["s_model.evaluate(testset)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["!mkdir saved_final_smodel"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./saved_final_smodel/model\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./saved_final_smodel/model\\assets\n"]}],"source":["s_model.save('./saved_final_smodel/model')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('eon')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"7ac21e7c5f840be57102ee0f5398c792063c2a27dc2325b7f7034b34f50df51e"}}},"nbformat":4,"nbformat_minor":4}
